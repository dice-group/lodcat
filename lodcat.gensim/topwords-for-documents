#!/usr/bin/env python3
from lxml import etree
from tqdm import tqdm
import argparse
import csv
import logging
import os
import pathlib
import collections


def cleanup_etree(elem):
    elem.clear()
    while elem.getprevious() is not None:
        del elem.getparent()[0]


def read_documents(file):
    total = 0
    for action, elem in etree.iterparse(file, events=('end',), recover=True, huge_tree=True):
        localname = etree.QName(elem).localname
        if localname == 'Document':
            name = elem.xpath('*[local-name()="DocumentName"]')
            # assert len(name) == 1
            text = elem.xpath('*[local-name()="DocumentText"]')
            # assert len(text) == 1 # sometimes DocumentText is missing
            if len(name) == 1 and len(text) == 1:
                name = name[0].text
                text = text[0].text
                yield name, text
            total += 1
            if total % 10000 == 0:
                logging.debug('Documents processed: %d', total)
            cleanup_etree(elem)


TOP_N = 10

logging.basicConfig(level=logging.DEBUG)

parser = argparse.ArgumentParser()
parser.add_argument('--names', dest='names_filter', required=True, help='file with document names')
parser.add_argument('--corpora', dest='input_dir', required=True, help='directory with XML corpora')
parser.add_argument('--output', dest='output_dir', required=True, help='output directory')
args = parser.parse_args()

names = set(open(args.names_filter).read().splitlines())

os.makedirs(args.output_dir, exist_ok=True)

for file in tqdm(pathlib.Path(args.input_dir).rglob('*.xml')):
    for name, text in read_documents(str(file)):
        if name in names:
            with open(os.path.join(args.output_dir, f'{name}.top_words'), 'w') as csvfile:
                csvwriter = csv.writer(csvfile)
                csvwriter.writerow(['topic_id'] + [f'term{i}' for i in range(TOP_N)])
                csvwriter.writerow([0] + [z[0] for z in collections.Counter(text.split()).most_common(TOP_N)])
