#!/usr/bin/env python3
from gensim.corpora.dictionary import Dictionary
from gensim.models import LdaModel
from lxml import etree
from tqdm import tqdm
import argparse
import csv
import logging
import os


def cleanup_etree(elem):
    elem.clear()
    while elem.getprevious() is not None:
        del elem.getparent()[0]


def classify_text(model, dictionary, text):
    return model.get_document_topics(bow=dictionary.doc2bow(text.split()), minimum_probability=0)


def classify_docs_file(model, dictionary, file):
    total = 0
    for action, elem in etree.iterparse(file, events=('end',), recover=True, huge_tree=True):
        localname = etree.QName(elem).localname
        if localname == 'Document':
            name = elem.xpath('*[local-name()="DocumentName"]')
            # assert len(name) == 1
            text = elem.xpath('*[local-name()="DocumentText"]')
            # assert len(text) == 1 # sometimes DocumentText is missing
            if len(name) == 1 and len(text) == 1:
                name = name[0].text
                text = text[0].text
                yield name, classify_text(model, dictionary, text)
            total += 1
            if total % 10000 == 0:
                logging.debug('Documents processed: %d', total)
            cleanup_etree(elem)


MODEL_FILE = 'gensim-ldamodel'

logging.basicConfig(level=logging.DEBUG)

parser = argparse.ArgumentParser()
parser.add_argument('--model-dir', dest='model_dir', required=True)
parser.add_argument('--dictionary', dest='dictionary_file', required=True)
parser.add_argument('--docs-dir', dest='docs_dir', required=True)
parser.add_argument('--output-file', dest='output_file', required=True)
args = parser.parse_args()

dictionary = Dictionary.load(args.dictionary_file)

model_file = os.path.join(args.model_dir, MODEL_FILE)
model = LdaModel.load(model_file)
logging.info(f'Model: {model}')

os.makedirs(os.path.dirname(args.output_file), exist_ok=True)
with open(args.output_file, 'w') as csvfile:
    csvwriter = csv.writer(csvfile)
    files = [os.path.join(args.docs_dir, f) for f in os.listdir(args.docs_dir)]
    files = [f for f in files if os.path.isfile(f) and f.endswith('.xml')]
    with tqdm(files) as tfiles:
        for f in tfiles:
            tfiles.set_postfix_str(os.path.basename(f))
            for name, data in classify_docs_file(model, dictionary, f):
                data = {k: v for k, v in data}
                probabilities = [data.get(i, 0) for i in range(model.num_topics)]
                topic = probabilities.index(max(probabilities))
                csvwriter.writerow([name, '', topic] + probabilities)
